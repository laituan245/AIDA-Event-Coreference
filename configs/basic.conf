basic {
  # Data-Related Configs
  use_groundtruth = true

  # Model-Related Configs
  transformer = xlm-roberta-base
  multi_piece_strategy = average
  ffnn_size = 500
  ffnn_depth = 2
  feature_size = 50

  # Additional Features Configs
  use_event_type_features = true

  # Training/Inference Configs
  gradient_checkpointing = true
  transformer_learning_rate = 5e-05
  task_learning_rate = 0.0005
  epochs = 50
  batch_size = 8
  dropout_rate = 0.5
  transformer_dropout_rate = 0.5
  max_grad_norm = 1.0
  transformer_weight_decay = 0.1

  # Others
  no_cuda = false
  report_frequency = 100
}
